import matplotlib.pyplot as plt
import numpy as np
from sklearn import cluster, datasets, manifold, metrics, random_projection
from sklearn.preprocessing import MinMaxScaler
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from matplotlib.axes._axes import _log as matplotlib_axes_logger
# Stop printing small error
matplotlib_axes_logger.setLevel('ERROR')

# prepare data
digits = datasets.load_digits()
# digits datasets. a dict. 2 important keys: 'dat
print("Data keys: ", digits.keys())
print("Dataset size: ", digits['data'].shape, "\n", "Target size: ",
      digits['target'].shape)

### you can also perform this transformation with sklearn.preprocessing.StandardScaler()
_data_std = StandardScaler().fit_transform(digits['data'])
### By default, sklearn will avoid "divided by zero" and return zeros instead of "nan"

# PCA to 2D
pca = PCA(n_components=20)
x_pca_2 = pca.fit_transform(digits['data'])[:, 0:2]
print(x_pca_2.shape)

# Visualization (using pyplot)
fig = plt.figure(figsize=(6, 6), dpi=120)
plt.xlabel('PC1')
plt.xlabel('PC2')
plt.title("1-2 PCA Result")
category_colors = plt.get_cmap('tab10')(np.linspace(0., 1., 10))
scatter = plt.scatter(x_pca_2[:, 0],
                      x_pca_2[:, 1],
                      c=category_colors[digits['target']])

plt.legend(*scatter.legend_elements(), loc="best", title="Classes")
plt.savefig(".\\AI\\AI_in_chem\\homework4\\1-2.png")